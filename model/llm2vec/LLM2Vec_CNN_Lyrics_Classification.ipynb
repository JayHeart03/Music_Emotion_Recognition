{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "import-libraries",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "from llm2vec import LLM2Vec\n",
                "import nltk\n",
                "from nltk.tokenize import word_tokenize\n",
                "from nltk.corpus import stopwords\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from keras.models import Model\n",
                "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout, concatenate\n",
                "from keras.utils import to_categorical\n",
                "from keras.callbacks import LearningRateScheduler\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
                "from keras.optimizers import Adam\n",
                "\n",
                "# 下载 NLTK 资源\n",
                "nltk.download('punkt')\n",
                "nltk.download('stopwords')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load-data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 数据集路径\n",
                "dataset_path = \"D:/Project/yxz1225/data/data_moody/MoodyLyrics4Q.csv\"\n",
                "\n",
                "# 加载数据\n",
                "data = pd.read_csv(dataset_path)\n",
                "data = data.sample(frac=1, random_state=42).reset_index(drop=True)  # 打乱数据\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "text-preprocessing",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 数据预处理\n",
                "def preprocess_text(text):\n",
                "    tokens = word_tokenize(text)\n",
                "    stop_words = set(stopwords.words('english'))\n",
                "    cleaned = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
                "    return ' '.join(cleaned)\n",
                "\n",
                "data['processed_lyrics'] = data['lyrics'].apply(preprocess_text)\n",
                "data[['lyrics', 'processed_lyrics']].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "encode-labels",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 处理类别标签\n",
                "label_encoder = LabelEncoder()\n",
                "encoded_labels = label_encoder.fit_transform(data['mood'])\n",
                "labels = to_categorical(encoded_labels)\n",
                "\n",
                "# 检查类别\n",
                "label_encoder.classes_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "llm2vec-embedding",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 使用 LLM2Vec 获取嵌入\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "\n",
                "l2v = LLM2Vec.from_pretrained(\n",
                "    \"McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp\",\n",
                "    peft_model_name_or_path=\"McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-unsup-simcse\",\n",
                "    device_map=device,\n",
                "    torch_dtype=torch.bfloat16,\n",
                ")\n",
                "\n",
                "def get_llm2vec_embedding(text):\n",
                "    return l2v.encode(text)\n",
                "\n",
                "data['llm2vec_embedding'] = data['processed_lyrics'].apply(get_llm2vec_embedding)\n",
                "X_llm2vec = np.vstack(data['llm2vec_embedding'].values)  # 形状: (num_samples, embedding_dim)\n",
                "embedding_dim = X_llm2vec.shape[1]  # 获取 LLM2Vec 维度"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train-test-split",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 划分训练集\n",
                "x_train, x_val, y_train, y_val = train_test_split(X_llm2vec, labels, test_size=0.2, random_state=42, stratify=labels)\n",
                "\n",
                "print(f\"训练数据形状: {x_train.shape}\")\n",
                "print(f\"测试数据形状: {x_val.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "build-cnn-model",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 构建 CNN 分类模型\n",
                "input_layer = Input(shape=(embedding_dim,), name='LLM2Vec_Input')\n",
                "\n",
                "dense1 = Dense(128, activation='relu', name='Dense1')(input_layer)\n",
                "dropout1 = Dropout(0.2, name='Dropout1')(dense1)\n",
                "dense2 = Dense(64, activation='relu', name='Dense2')(dropout1)\n",
                "dropout2 = Dropout(0.2, name='Dropout2')(dense2)\n",
                "output_layer = Dense(len(labels[0]), activation='softmax', name='Output')(dropout2)\n",
                "\n",
                "model = Model(inputs=input_layer, outputs=output_layer)\n",
                "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train-model",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 训练模型\n",
                "history = model.fit(x_train, y_train,\n",
                "                    batch_size=16,\n",
                "                    epochs=20,\n",
                "                    validation_data=(x_val, y_val),\n",
                "                    verbose=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "evaluate-model",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 评估模型\n",
                "y_pred = model.predict(x_val)\n",
                "y_pred_classes = np.argmax(y_pred, axis=1)\n",
                "y_true = np.argmax(y_val, axis=1)\n",
                "\n",
                "print(classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_))\n",
                "print(f'F1 Score: {f1_score(y_true, y_pred_classes, average=\"weighted\"):.2f}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
